import csv
import psycopg2
from psycopg2 import sql
from io import StringIO
import argparse
import logging
import sys
import datetime
import os
import tempfile
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
# -----------------------------------------------------------
# ğŸª¶ ë¡œê¹… ì„¤ì •
# -----------------------------------------------------------
def setup_logger(script_name):
    log_dir = os.getenv("LOG_DIR", "./logs")  # ê¸°ë³¸ ë¡œê·¸ ë””ë ‰í† ë¦¬
    log_file_path = os.path.join(log_dir, f"{script_name}.log")  # íŒŒì¼ëª… ë™ì  ì„¤ì •

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    logger = logging.getLogger(script_name)
    if not logger.handlers:  # ì¤‘ë³µ ë°©ì§€
        logging.basicConfig(
            filename=log_file_path,
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S"
        )
        console = logging.StreamHandler()
        console.setLevel(logging.INFO)
        formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
        console.setFormatter(formatter)
        logger.addHandler(console)
        logger.info("ğŸ“˜ Logging initialized.")
    return logger

# -----------------------------------------------------------
# âš™ï¸ ì•ˆì „í•œ float ë³€í™˜ í•¨ìˆ˜
# -----------------------------------------------------------
def safe_float(x):
    try:
        return float(x)
    except (TypeError, ValueError):
        return 0.0

# -----------------------------------------------------------
# ğŸ“… ì›”ë³„ íŒŒí‹°ì…˜ ìë™ ìƒì„± í•¨ìˆ˜
# -----------------------------------------------------------
def ensure_partition(cur, etl_ymd_str):
    """etl_ymd ê°’(YYYY-MM-DD) ê¸°ì¤€ìœ¼ë¡œ ì›”ë³„ íŒŒí‹°ì…˜ ìƒì„±"""
    ymd = datetime.datetime.strptime(etl_ymd_str, "%Y-%m-%d").date()
    start = ymd.replace(day=1)
    next_month = (start.replace(day=28) + datetime.timedelta(days=4)).replace(day=1)

    partition_name = f"yeosu_dm.tb_flowpop_{start.strftime('%Y%m')}"
    sql_query = sql.SQL("""
    CREATE TABLE IF NOT EXISTS {partition_name}
        PARTITION OF yeosu_dm.tb_flowpop
        FOR VALUES FROM (%s) TO (%s);
    CREATE INDEX IF NOT EXISTS {index_name}
        ON {partition_name} (timezn_cd, etl_ymd);
    """).format(
        partition_name=sql.Identifier(partition_name),
        index_name=sql.Identifier(f"idx_tb_flowpop_{start.strftime('%Y%m')}_timezn_ymd")
    )

    cur.execute(sql_query, [str(start), str(next_month)])
    logger.info(f"ğŸ“¦ íŒŒí‹°ì…˜ í™•ì¸/ìƒì„± ì™„ë£Œ: {partition_name}")
    return partition_name

# -----------------------------------------------------------
# ğŸš€ ë©”ì¸ ETL ë¡œì§
# -----------------------------------------------------------
def load_flowpop(input_file):
    logger.info(f"ì‹œì‘: {input_file} íŒŒì¼ì„ PostgreSQLë¡œ ì ì¬í•©ë‹ˆë‹¤.")

    conn = psycopg2.connect(
        dbname=os.getenv("DB_NAME", "postgres"),
        user=os.getenv("DB_USER", "root"),
        password=os.getenv("DB_PASS", "password"),
        host=os.getenv("DB_HOST", "localhost"),
        port=os.getenv("DB_PORT", "5432")
    )
    cur = conn.cursor()

    # -----------------------------------------------------------
    # âš™ï¸ ì œê±°í•  ì»¬ëŸ¼ ëª©ë¡
    # -----------------------------------------------------------
    columns_to_exclude = [
        'x', 'y',
        'm00', 'm15', 'm25', 'm35', 'm45', 'm55', 'm65',
        'f00', 'f15', 'f25', 'f35', 'f45', 'f55', 'f65',
        'admi_cd'
    ]

    # -----------------------------------------------------------
    # ğŸ“¥ CSV ì½ê¸°
    # -----------------------------------------------------------
    with tempfile.NamedTemporaryFile(mode='w+', delete=False) as temp_file:
        reader = csv.DictReader(open(input_file, 'r', encoding='utf-8', newline=''), delimiter='|')
        all_columns = reader.fieldnames
        selected_columns = [c for c in all_columns if c not in columns_to_exclude]
        final_columns = selected_columns
        writer = csv.writer(temp_file, delimiter=',')

        first_etl_ymd = None
        row_count = 0

        for row in reader:
            # etl_ymd ì¶”ì¶œ (ìµœì´ˆ í•œ ë²ˆë§Œ)
            if first_etl_ymd is None:
                first_etl_ymd = row['etl_ymd']

            # ì„±ë³„Â·ì—°ë ¹ëŒ€ í•©ì‚° (float ê¸°ë°˜)
            row['m10'] = safe_float(row['m00']) + safe_float(row['m10']) + safe_float(row['m15'])
            row['m20'] = safe_float(row['m20']) + safe_float(row['m25'])
            row['m30'] = safe_float(row['m30']) + safe_float(row['m35'])
            row['m40'] = safe_float(row['m40']) + safe_float(row['m45'])
            row['m50'] = safe_float(row['m50']) + safe_float(row['m55'])
            row['m60'] = safe_float(row['m60']) + safe_float(row['m65'])

            row['f10'] = safe_float(row['f00']) + safe_float(row['f10']) + safe_float(row['f15'])
            row['f20'] = safe_float(row['f20']) + safe_float(row['f25'])
            row['f30'] = safe_float(row['f30']) + safe_float(row['f35'])
            row['f40'] = safe_float(row['f40']) + safe_float(row['f45'])
            row['f50'] = safe_float(row['f50']) + safe_float(row['f55'])
            row['f60'] = safe_float(row['f60']) + safe_float(row['f65'])

            # í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
            for c in columns_to_exclude:
                row.pop(c, None)

            # CSV ë²„í¼ ê¸°ë¡
            writer.writerow([row[c] for c in final_columns])

            row_count += 1
            if row_count % 500000 == 0:
                logger.info(f"ì§„í–‰ ì¤‘: {row_count:,}í–‰ ì²˜ë¦¬ ì™„ë£Œ")

        temp_file.flush()

    if not first_etl_ymd:
        logger.error("âŒ etl_ymd ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    logger.info(f"ì´ {row_count:,}í–‰ ë³€í™˜ ì™„ë£Œ (etl_ymd={first_etl_ymd})")

    # -----------------------------------------------------------
    # ğŸ§± íŒŒí‹°ì…˜ ìë™ ìƒì„±
    # -----------------------------------------------------------
    partition_name = ensure_partition(cur, first_etl_ymd)

    # -----------------------------------------------------------
    # ğŸ“¨ COPY ìˆ˜í–‰
    # -----------------------------------------------------------
    with open(temp_file.name, 'r') as temp_file_read:
        logger.info(f"PostgreSQL COPY ì‹œì‘ â†’ {partition_name}")
        cur.copy_expert(f"""
            COPY {partition_name} ({', '.join(final_columns)})
            FROM STDIN WITH (FORMAT CSV)
        """, temp_file_read)

    conn.commit()
    cur.close()
    conn.close()

    logger.info(f"âœ… ë°ì´í„° ì ì¬ ì™„ë£Œ: {partition_name}, ì´ {row_count:,}í–‰")

# -----------------------------------------------------------
# ğŸ§­ ì‹¤í–‰ë¶€
# -----------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="FLOWPOP ì›”ë³„ ë°ì´í„° ì ì¬ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--input", required=True, help="ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ")
    logger = setup_logger("flowpop")
    logger.info("â–¶ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    args = parser.parse_args()

    try:
        load_flowpop(args.input)
    except Exception as e:
        logger.exception(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)