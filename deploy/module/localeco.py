import argparse
import pandas as pd
import json
import os
from datetime import datetime
import glob
from utils import setup_logger, get_engine_from_env, get_src_dir

# =========================
# ğŸ“ ê³µí†µ ê²½ë¡œ ì •ì˜
# =========================
BASE_DIR = get_src_dir()
KCB_PATTERN = os.path.join(BASE_DIR, "YEOSU_SOHO_STAT_*")
IND_PATTERN = os.path.join(BASE_DIR, "YEOSU_IND_CODE*")
LOCAL_PAY_PATTERN = os.path.join(BASE_DIR, "local_pay_*")
LOCAL_GRID_JSON = os.path.join(BASE_DIR, "json/local_grid_id.json")

# ------------------------------------------------------------------------
# KCB ë°ì´í„° ì²˜ë¦¬ ë° ì ì¬
# ------------------------------------------------------------------------
def process_kcb(logger):
    logger.info("ğŸš€ KCB ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    kcb_files = sorted(glob.glob(KCB_PATTERN))
    ind_files = sorted(glob.glob(IND_PATTERN))
    if not kcb_files or not ind_files:
        logger.error("âŒ KCB ë˜ëŠ” ì—…ì¢…ì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    kcb_file = kcb_files[-1]
    ind_file = ind_files[-1]
    logger.info(f"KCB íŒŒì¼: {kcb_file}, ì—…ì¢…ì½”ë“œ íŒŒì¼: {ind_file}")

    kcb = pd.read_csv(kcb_file, sep='|')
    ind_code = pd.read_csv(ind_file, sep='|')
    kcb = pd.merge(kcb, ind_code, left_on='SIC_CD_LV4', right_on='SIC_CD', how='inner').drop(columns='SIC_CD')
    drop_cols = [
        'WGS84_X', 'WGS84_Y', 'UTMK_X', 'UTML_Y',
        'RUN_OUT2_CNT', 'TOT_SALES_AMT1_CNT', 'TOT_SALES_AMT2_CNT',
        'TOT_SALES_AMT3_CNT', 'TOT_SALES_AMT4_CNT'
    ]
    kcb.drop(columns=drop_cols, inplace=True)
    kcb = kcb[[
        'QID50', 'BS_YR_MON', 'SIC_CD_LV4','SIC_FST_CLSFY_ITM_NM', 'SIC_SCND_CLSFY_ITM_NM',
        'SHOP_CNT', 'OP_CNT', 'NEW_OPN_CNT', 'RUN_OUT_CNT', 'TOT_SALE_AMT', 'TOT_SALES_AMT0_CNT', 'TOT_SALES_AMT5_CNT',]]
    kcb.columns = [col.lower() for col in kcb.columns]
    kcb.rename(columns={
        'qid50': 'grid_id',
        'bs_yr_mon': 'std_ym',
        'tot_sales_amt5_cnt': 'tot_sales_amt5m_cnt'
    }, inplace=True)
    kcb['grid_id'] = kcb['grid_id'].astype(str)
    kcb['std_ym'] = kcb['std_ym'].astype(str)
    kcb["reg_dttm"] = datetime.now()
    logger.info(f"KCB ë°ì´í„° ì •ì œ ì™„ë£Œ: {kcb.shape[0]} rows, {kcb.shape[1]} columns")
    engine = get_engine_from_env()
    kcb.to_sql(name='tb_kcb_stat', con=engine, if_exists='append', index=False, method='multi')
    logger.info("âœ… KCB ë°ì´í„° DB ì ì¬ ì™„ë£Œ")

# ------------------------------------------------------------------------
# Local Pay ë°ì´í„° ì²˜ë¦¬ ë° ì ì¬
# ------------------------------------------------------------------------
def process_local(logger):
    logger.info("ğŸš€ Local Pay ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    pay_files = sorted(glob.glob(LOCAL_PAY_PATTERN))
    if not pay_files or not os.path.exists(LOCAL_GRID_JSON):
        logger.error("âŒ Local Pay íŒŒì¼ ë˜ëŠ” grid_id íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    pay_file = pay_files[-1]
    logger.info(f"Local Pay íŒŒì¼: {pay_file}, grid_id íŒŒì¼: {LOCAL_GRID_JSON}")

    local_pay = pd.read_csv(pay_file)
    with open(LOCAL_GRID_JSON, 'r', encoding='utf-8') as f:
        local_grid_id = json.load(f)
    local_pay['ê²°ì œë…„ì›”ì¼'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”ì¼'])
    local_pay['ê²°ì œë…„ì›”'] = local_pay['ê²°ì œë…„ì›”ì¼'].dt.strftime('%Y-%m')
    local_pay['grid_id'] = local_pay['ê°€ë§¹ì ëª…'].map(local_grid_id)
    local_pay['std_ym'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”']).dt.strftime("%Y%m")
    local_pay_agg = local_pay.groupby(['ì—…ì¢…', 'grid_id', 'std_ym'], as_index=False).agg(
        pay_cnt=('ë²ˆí˜¸', 'count'),
        pay_amt=('ê²°ì œê¸ˆì•¡', 'sum')
    )[['grid_id', 'std_ym', 'ì—…ì¢…', 'pay_cnt', 'pay_amt']]
    local_pay_agg.rename(columns={'ì—…ì¢…': 'ind_type'}, inplace=True)
    local_pay_agg['reg_dttm'] = datetime.now()
    local_pay_agg['grid_id'] = local_pay_agg['grid_id'].astype(str)
    logger.info(f"Local Pay ì§‘ê³„ ì™„ë£Œ: {local_pay_agg.shape[0]} rows")
    engine = get_engine_from_env()
    local_pay_agg.to_sql(name='tb_local_pay_agg', con=engine, if_exists='append', index=False, method='multi')
    logger.info("âœ… Local Pay ë°ì´í„° DB ì ì¬ ì™„ë£Œ")

# ------------------------------------------------------------------------
# Local Pay ë°ì´í„° ì²˜ë¦¬ ë° ì ì¬ (ì›ë³¸ ê·¸ëŒ€ë¡œ)
# ------------------------------------------------------------------------
def process_local2(logger):
    logger.info("ğŸš€ Local Pay ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    pay_files = sorted(glob.glob(LOCAL_PAY_PATTERN))

    if not pay_files or not os.path.exists(LOCAL_GRID_JSON):
        logger.error("âŒ Local Pay íŒŒì¼ ë˜ëŠ” grid_id íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    pay_file = pay_files[-1]
    logger.info(f"Local Pay íŒŒì¼: {pay_file}, grid_id íŒŒì¼: {LOCAL_GRID_JSON}")

    local_pay = pd.read_csv(pay_file)

    # grid JSON ë¡œë“œ
    with open(LOCAL_GRID_JSON, 'r', encoding='utf-8') as f:
        local_grid_id = json.load(f)

    # ë‚ ì§œ ë³€í™˜
    local_pay['ê²°ì œë…„ì›”ì¼'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”ì¼'], format='%Y-%m-%d', errors='coerce')
    local_pay['ìƒë…„ì›”ì¼'] = pd.to_datetime(local_pay['ìƒë…„ì›”ì¼'], format='%Y%m%d', errors='coerce')

    # ê¸°ë³¸ ì „ì²˜ë¦¬
    local_pay['ê²°ì œë…„ì›”'] = local_pay['ê²°ì œë…„ì›”ì¼'].dt.strftime('%Y-%m')
    local_pay['grid_id'] = local_pay['ê°€ë§¹ì ëª…'].map(local_grid_id)
    local_pay['std_ym'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”']).dt.strftime("%Y%m")

    # ---------------------------------------------------------
    # ğŸ”¥ ë§Œ ë‚˜ì´ ê³„ì‚° (ì •í™•í•˜ê³  ì•ˆì •ì ì¸ pandas ê³µì‹)
    # ---------------------------------------------------------
    pay = local_pay["ê²°ì œë…„ì›”ì¼"]
    birth = local_pay["ìƒë…„ì›”ì¼"]

    local_pay["ë‚˜ì´"] = (pay.dt.year - birth.dt.year - ((pay.dt.month < birth.dt.month) | ((pay.dt.month == birth.dt.month) & (pay.dt.day < birth.dt.day))).astype(int)).astype("Int64")
    # ---------------------------------------------------------

    # ì—°ë ¹ëŒ€ êµ¬ê°„í™”
    bins = [10, 20, 30, 40, 50, 60, 70, 200]
    labels = ["10ëŒ€ ì´í•˜", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€", "70ëŒ€ì´ìƒ"]
    local_pay["ì—°ë ¹ëŒ€"] = pd.cut(local_pay["ë‚˜ì´"], bins=bins, labels=labels)

    # ì¶”ê°€ í•„ë“œ
    local_pay['grid_id'] = local_pay['grid_id'].astype(str)
    local_pay['reg_dttm'] = datetime.now()

    # ì œê±°í•  ì»¬ëŸ¼
    local_pay.drop(columns=['ë²ˆí˜¸',"ê±°ì£¼ì§€ì£¼ì†Œ","ê°€ë§¹ì ì£¼ì†Œ"], inplace=True, errors='ignore')

    # DB ì ì¬
    engine = get_engine_from_env()
    local_pay.to_sql(name='tb_local_pay_raw', con=engine, if_exists='append', index=False, method='multi')

    logger.info("âœ… Local Pay ë°ì´í„° DB ì ì¬ ì™„ë£Œ")

# ------------------------------------------------------------------------
# Main Entry
# ------------------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="KCB / Local Pay ë°ì´í„° ì²˜ë¦¬ ë° DB ì ì¬")
    parser.add_argument("target", type=str, choices=["kcb", "local","all","local2"], help="ì²˜ë¦¬í•  ë°ì´í„° ì¢…ë¥˜ ì„ íƒ")
    args = parser.parse_args()
    logger = setup_logger(f"LocalEconomy-{args.target.upper()}")
    logger.info(f"â–¶ ì‹¤í–‰ ëŒ€ìƒ: {args.target.upper()}")
    try:
        if args.target == "kcb":
            process_kcb(logger)
        elif args.target == "local":
            process_local(logger)
        elif args.target == "all":
            process_kcb(logger)
            process_local(logger)
        elif args.target == "local2":
            process_local2(logger)
    except Exception as e:
        logger.exception(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")