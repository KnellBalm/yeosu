import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
pd.set_option('mode.chained_assignment',  None) # <==== ê²½ê³ ë¥¼ ëˆë‹¤
from sqlalchemy import text
from datetime import datetime, timedelta
from utils import *
import re
import json

# ===============================
# ğŸ“˜ 1. SQL íŒŒì„œ
# ===============================
def load_sql_sections(file_path: str) -> dict[str, str]:
    """
    í•˜ë‚˜ì˜ .sql íŒŒì¼ ì•ˆì˜ ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ì£¼ì„ êµ¬ë¶„ì(-- [ì¿¼ë¦¬ëª…]) ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    queries = {}
    current_name = None
    buffer = []
    pattern = re.compile(r"--\s*\[(.*?)\]")

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            match = pattern.match(line.strip())
            if match:
                if current_name and buffer:
                    queries[current_name] = "\n".join(buffer).strip()
                    buffer = []
                current_name = match.group(1).strip()
            elif not line.strip().startswith("--"):
                buffer.append(line.rstrip())
        if current_name and buffer:
            queries[current_name] = "\n".join(buffer).strip()
    return queries


# ===============================
# ğŸ§© 2. SQL ì‹¤í–‰ / ì ì¬ í•¨ìˆ˜
# ===============================
def run_sql(engine, query: str, params: dict | None = None) -> pd.DataFrame:
    with engine.connect() as conn:
        result = conn.execute(text(query), params or {})
        df = pd.DataFrame(result.fetchall(), columns=result.keys())
    return df


def write_to_db(df: pd.DataFrame, table_name: str, engine, schema: str = None, if_exists: str = "replace"):
    df.to_sql(
        name=table_name,
        con=engine,
        schema=schema,
        if_exists=if_exists,
        index=False,
        method="multi"
    )

# ===============================
# ğŸ§¹ 3. ì „ì²˜ë¦¬ í•¨ìˆ˜
# ===============================
def make_binding_key(row, rd_col, main_col, sub_col):
    rd_val = row[rd_col]
    main_val = row[main_col]
    sub_val = row[sub_col]

    # ğŸš¨ ë³¸ë²ˆì´ ì—†ìœ¼ë©´ ì¦‰ì‹œ undefined
    if pd.isna(main_val) or str(main_val).strip() == "":
        return "undefined"

    # ë„ë¡œëª…ì½”ë“œê°€ ì—†ìœ¼ë©´ undefined (ë²•ì •ë™ì¼ ê²½ìš° regn_colì„ ì „ë‹¬í•¨)
    if pd.isna(rd_val) or str(rd_val).strip() == "":
        return "undefined"

    def to_int_str(val):
        try:
            if pd.isna(val) or str(val).strip() == "":
                return None
            return str(int(float(val)))
        except:
            return None

    rd_str = to_int_str(rd_val)
    main_str = to_int_str(main_val)
    sub_str = to_int_str(sub_val)

    if rd_str is None or main_str is None:
        return "undefined"

    if sub_str:
        return f"{rd_str}-{main_str}-{sub_str}"
    else:
        return f"{rd_str}-{main_str}"

def find_full_addr_id(
    row,
    rd_col="jumin_rd_code",
    main_col="jumin_bdng_orgno",
    sub_col="jumin_bdng_subno",
    regn_col="jumin_regn_code",
    san_col="jumin_san"
):
    rd_val = row[rd_col]
    main_val = row[main_col]

    # ğŸš¨ ë³¸ë²ˆì´ ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ undefined
    if pd.isna(main_val) or str(main_val).strip() == "":
        return "undefined"

    # =============================
    # 1) ë„ë¡œëª… ê¸°ë°˜
    # =============================
    if not pd.isna(rd_val) and str(rd_val).strip() != "":
        base = make_binding_key(row, rd_col, main_col, sub_col)
    else:
        # =============================
        # 2) ë„ë¡œëª… ì—†ìŒ â†’ ë²•ì •ë™ ê¸°ë°˜
        # =============================
        base = make_binding_key(row, regn_col, main_col, sub_col)

    if base == "undefined":
        return "undefined"

    # base: "code-main" ë˜ëŠ” "code-main-sub"
    parts = base.split("-")
    code = parts[0]
    main_sub = parts[1:]

    try:
        san = int(float(row[san_col]))
    except:
        san = 1

    # main-sub êµ¬ì¡° ì²˜ë¦¬
    if len(main_sub) == 2:
        main, sub = main_sub
        main = f"S{main}" if san == 2 else main
        result = f"{code}-{main}-{sub}"
    else:
        main = main_sub[0]
        main = f"S{main}" if san == 2 else main
        result = f"{code}-{main}"

    return result


# ===============================
# ğŸ“¦ 4. ë§¤í•‘ ë°ì´í„° ë¡œë“œ
# ===============================
addr_id_map = json.load(open("../data/json/addr_id_map.json"))
pop_grid_id = json.load(open("../data/json/pop_grid_id.json"))

# ===============================
# ğŸ§¹ 5. ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ===============================
def preprocess_household(df: pd.DataFrame, addr_id_map: dict, pop_grid_id: dict) -> pd.DataFrame:
    # 1) ì£¼ì†Œ ë§¤í•‘
    df['full_addr_id'] = df.apply(find_full_addr_id, axis=1)
    df['full_addr_name'] = df['full_addr_id'].map(addr_id_map)

    # 2) grid ë§¤í•‘
    df['grid_id'] = df['full_addr_name'].map(pop_grid_id)

    # 3) ìœ íš¨ gridë§Œ ë‚¨ê¸°ê¸°
    df = df[df['grid_id'].notnull() & (df['grid_id'].str.len() == 8)]
    df['grid_id'] = df['grid_id'].astype(str)

    # 4) ì„¸ëŒ€ ê·œëª¨ ì§‘ê³„
    gb_df = df.groupby(['grid_id'], as_index=False).agg(
        total_household_cnt=('jumin_head_sid', 'count'),
        mem_cnt1=('member_count', lambda x: (x == 1).sum()),
        mem_cnt2=('member_count', lambda x: (x == 2).sum()),
        mem_cnt3=('member_count', lambda x: (x == 3).sum()),
        mem_cnt4=('member_count', lambda x: (x >= 4).sum()),
    )
    return gb_df

def preprocess_inflow(df: pd.DataFrame, addr_id_map: dict, pop_grid_id: dict) -> pd.DataFrame:
    df['full_addr_id'] = df.apply(
        lambda row: find_full_addr_id(
            row,
            rd_col="jumin_inr_rd_code",
            main_col="jumin_inr_bdng_orgno",
            sub_col="jumin_inr_bdng_subno",
            regn_col="jumin_inr_regn_code",
            san_col="jumin_inr_san"
        ),
        axis=1
    )
    df['full_addr_name'] = df['full_addr_id'].map(addr_id_map)
    df['grid_id'] = df['full_addr_name'].map(pop_grid_id)
    df['gens'] = (df['age'] // 10 * 10).astype(int)
    df = df[df['grid_id'].notnull() & (df['grid_id'].str.len() == 8)]
    df['grid_id'] = df['grid_id'].astype(str)
    df['gender'] = df['gender'].astype(str)
    df['gens'] = df['gens'].astype(str)
    df = df.groupby(['grid_id', 'gender', 'gens'], as_index=False).agg(
        member_cnt=('jumin_sid', 'count')
    )
    return df

def preprocess_outflow(df: pd.DataFrame, addr_id_map: dict, pop_grid_id: dict) -> pd.DataFrame:
    df['full_addr_id'] = df.apply(
        lambda row: find_full_addr_id(
            row,
            rd_col="jumin_exr_rd_code",
            main_col="jumin_exr_bdng_orgno",
            sub_col="jumin_exr_bdng_subno",
            regn_col="jumin_exr_regn_code",
            san_col="jumin_exr_san"
        ),
        axis=1
    )
    df['full_addr_name'] = df['full_addr_id'].map(addr_id_map)
    df['grid_id'] = df['full_addr_name'].map(pop_grid_id)
    df['gens'] = (df['age'] // 10 * 10).astype(int)
    df = df[df['grid_id'].notnull() & (df['grid_id'].str.len() == 8)]
    df['grid_id'] = df['grid_id'].astype(str)
    df['gender'] = df['gender'].astype(str)
    df['gens'] = df['gens'].astype(str)
    df = df.groupby(['grid_id', 'gender', 'gens'], as_index=False).agg(
        member_cnt=('jumin_sid', 'count')
    )
    return df

def preprocess_totpop(df: pd.DataFrame, addr_id_map: dict, pop_grid_id: dict) -> pd.DataFrame:
    df['full_addr_id'] = df.apply(find_full_addr_id, axis=1)
    df['full_addr_name'] = df['full_addr_id'].map(addr_id_map)
    df['grid_id'] = df['full_addr_name'].map(pop_grid_id)
    df['gens'] = (df['age'] // 10 * 10).astype(int)
    df = df[df['grid_id'].notnull() & (df['grid_id'].str.len() == 8)]
    df['grid_id'] = df['grid_id'].astype(str)
    df['gender'] = df['gender'].astype(str)
    df['gens'] = df['gens'].astype(str)
    df = df.groupby(['grid_id', 'gens', 'gender'], as_index=False).agg(
        member_cnt=('jumin_sid', 'count')
    )
    return df

## ==============================
# ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
## ==============================
def run_pipeline_step(step_name: str, query_key: str, preprocess_fn, output_table: str,
                      engine, queries, addr_id_map, pop_grid_id):
    logger.info(f"â–¶ {step_name} ì‹œì‘")

    df = run_sql(engine, queries[query_key])
    df = preprocess_fn(df, addr_id_map, pop_grid_id)
    write_to_db(df, output_table, engine)

    logger.info(f"âœ… {step_name} ì™„ë£Œ")



# ===============================
# ğŸš€ ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ===============================
logger = setup_logger("population")
logger.info("ğŸ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

engine = get_engine_from_env()
queries = load_sql_sections('../sql/yeosu_query_251113.sql')

pipeline_steps = [
    ("ì„¸ëŒ€ë³„", "1", preprocess_household, "tb_pop_household_count"),
    ("ì „ì…ì", "2", preprocess_inflow, "tb_pop_inflow_count"),
    ("ì „ì¶œì", "3", preprocess_outflow, "tb_pop_outflow_count"),
    ("ì´ì¸êµ¬", "4", preprocess_totpop, "tb_pop_total_count"),
]

for step_name, q_key, fn, table in pipeline_steps:
    run_pipeline_step(step_name, q_key, fn, table,
                      engine, queries, addr_id_map, pop_grid_id)

logger.info("ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
