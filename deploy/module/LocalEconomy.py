import argparse
import pandas as pd
import json
import os
from sqlalchemy import create_engine
from dotenv import load_dotenv
from datetime import datetime
import glob
from utils import setup_logger, get_engine_from_env

# =========================
# ğŸ“ ê³µí†µ ê²½ë¡œ ì •ì˜
# =========================
BASE_DIR = "/DATA/jupyter_WorkingDirectory/notebook/yeosu/deploy/data"
KCB_PATTERN = os.path.join(BASE_DIR, "YEOSU_SOHO_STAT_*.txt")
IND_PATTERN = os.path.join(BASE_DIR, "YEOSU_IND_CODE*.txt")
LOCAL_PAY_PATTERN = os.path.join(BASE_DIR, "local_pay_*.csv")
LOCAL_GRID_JSON = os.path.join(BASE_DIR, "json/local_grid_id.json")

# ------------------------------------------------------------------------
# KCB ë°ì´í„° ì²˜ë¦¬ ë° ì ì¬
# ------------------------------------------------------------------------
def process_kcb(logger):
    logger.info("ğŸš€ KCB ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    kcb_files = sorted(glob.glob(KCB_PATTERN))
    ind_files = sorted(glob.glob(IND_PATTERN))
    if not kcb_files or not ind_files:
        logger.error("âŒ KCB ë˜ëŠ” ì—…ì¢…ì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    kcb_file = kcb_files[-1]
    ind_file = ind_files[-1]
    logger.info(f"KCB íŒŒì¼: {kcb_file}, ì—…ì¢…ì½”ë“œ íŒŒì¼: {ind_file}")

    kcb = pd.read_csv(kcb_file, sep='|')
    ind_code = pd.read_csv(ind_file, sep='|')
    kcb = pd.merge(kcb, ind_code, left_on='SIC_CD_LV4', right_on='SIC_CD', how='inner').drop(columns='SIC_CD')
    drop_cols = [
        'WGS84_X', 'WGS84_Y', 'UTMK_X', 'UTML_Y',
        'RUN_OUT2_CNT', 'TOT_SALES_AMT1_CNT', 'TOT_SALES_AMT2_CNT',
        'TOT_SALES_AMT3_CNT', 'TOT_SALES_AMT4_CNT'
    ]
    kcb.drop(columns=drop_cols, inplace=True)
    kcb = kcb[[
        'QID50', 'BS_YR_MON', 'SIC_CD_LV4','SIC_FST_CLSFY_ITM_NM', 'SIC_SCND_CLSFY_ITM_NM',
        'SHOP_CNT', 'OP_CNT', 'NEW_OPN_CNT', 'RUN_OUT_CNT', 'TOT_SALE_AMT', 'TOT_SALES_AMT0_CNT',  'TOT_SALES_AMT5_CNT', ]]
    kcb.rename(columns={
        'QID50': 'grid_id',
        'BS_YR_MON': 'std_ym',
        'SIC_CD_LV4': 'sic_cd_lv4',
        'SIC_FST_CLSFY_ITM_NM': 'sic_fst_clsfy_itm_nm',
        'SIC_SCND_CLSFY_ITM_NM': 'sic_scnd_clsfy_itm_nm',
        'SHOP_CNT': 'shop_cnt',
        'OP_CNT': 'op_cnt',
        'NEW_OPN_CNT': 'new_opn_cnt',
        'RUN_OUT_CNT': 'run_out_cnt',
        'TOT_SALE_AMT': 'tot_sale_amt',
        'TOT_SALES_AMT0_CNT': 'tot_sales_amt0_cnt',
        'TOT_SALES_AMT5_CNT': 'tot_sales_amt5m_cnt'
    }, inplace=True)
    kcb["reg_dttm"] = datetime.now()
    logger.info(f"KCB ë°ì´í„° ì •ì œ ì™„ë£Œ: {kcb.shape[0]} rows, {kcb.shape[1]} columns")
    engine = get_engine_from_env()
    kcb.to_sql(name='tb_kcb_stat', con=engine, if_exists='append', index=False, chunksize=10000, method='multi')
    logger.info("âœ… KCB ë°ì´í„° DB ì ì¬ ì™„ë£Œ")

# ------------------------------------------------------------------------
# Local Pay ë°ì´í„° ì²˜ë¦¬ ë° ì ì¬
# ------------------------------------------------------------------------
def process_local(logger):
    logger.info("ğŸš€ Local Pay ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    pay_files = sorted(glob.glob(LOCAL_PAY_PATTERN))
    if not pay_files or not os.path.exists(LOCAL_GRID_JSON):
        logger.error("âŒ Local Pay íŒŒì¼ ë˜ëŠ” grid_id íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    pay_file = pay_files[-1]
    logger.info(f"Local Pay íŒŒì¼: {pay_file}, grid_id íŒŒì¼: {LOCAL_GRID_JSON}")

    local_pay = pd.read_csv(pay_file)
    with open(LOCAL_GRID_JSON, 'r', encoding='utf-8') as f:
        local_grid_id = json.load(f)
    local_pay['ê²°ì œë…„ì›”ì¼'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”ì¼'])
    local_pay['ê²°ì œë…„ì›”'] = local_pay['ê²°ì œë…„ì›”ì¼'].dt.strftime('%Y-%m')
    local_pay['grid_id'] = local_pay['ê°€ë§¹ì ëª…'].map(local_grid_id)
    local_pay['std_ym'] = pd.to_datetime(local_pay['ê²°ì œë…„ì›”']).dt.strftime("%Y%m")
    local_pay_agg = local_pay.groupby(['ì—…ì¢…', 'grid_id', 'std_ym'], as_index=False).agg(
        pay_cnt=('ë²ˆí˜¸', 'count'),
        pay_amt=('ê²°ì œê¸ˆì•¡', 'sum')
    )[['grid_id', 'std_ym', 'ì—…ì¢…', 'pay_cnt', 'pay_amt']]
    local_pay_agg['reg_dttm'] = datetime.now()
    logger.info(f"Local Pay ì§‘ê³„ ì™„ë£Œ: {local_pay_agg.shape[0]} rows")
    engine = get_engine_from_env()
    local_pay_agg.to_sql(name='tb_local_pay_agg', con=engine, if_exists='append', index=False, chunksize=100000, method='multi')
    logger.info("âœ… Local Pay ë°ì´í„° DB ì ì¬ ì™„ë£Œ")

# ------------------------------------------------------------------------
# Main Entry
# ------------------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="KCB / Local Pay ë°ì´í„° ì²˜ë¦¬ ë° DB ì ì¬")
    parser.add_argument("--target", type=str, required=True, choices=["kcb", "local"], help="ì²˜ë¦¬í•  ë°ì´í„° ì¢…ë¥˜ ì„ íƒ")
    args = parser.parse_args()
    logger = setup_logger(f"LocalEconomy-{args.target.upper()}")
    logger.info(f"â–¶ ì‹¤í–‰ ëŒ€ìƒ: {args.target.upper()}")
    try:
        if args.target == "kcb":
            process_kcb(logger)
        elif args.target == "local":
            process_local(logger)
    except Exception as e:
        logger.exception(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")